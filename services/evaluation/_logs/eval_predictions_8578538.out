=========================================================
SLURM JOB ID: 8578538
JOB NAME: eval_predictions
Running on nodes: cs-1-2
Number of GPUs allocated: 1
=========================================================
--- Python and Torch Diagnostics ---
/usr/bin/python
PyTorch version: 2.9.1+cu128
CUDA available: True
Number of GPUs: 1
------------------------------------
--- GPU Diagnostics ---
Wed Nov 19 11:33:26 2025       
+-----------------------------------------------------------------------------------------+
| NVIDIA-SMI 570.195.03             Driver Version: 570.195.03     CUDA Version: 12.8     |
|-----------------------------------------+------------------------+----------------------+
| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |
| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |
|                                         |                        |               MIG M. |
|=========================================+========================+======================|
|   0  NVIDIA A100-SXM4-80GB          Off |   00000000:07:00.0 Off |                    0 |
| N/A   35C    P0             63W /  400W |       0MiB /  81920MiB |      0%      Default |
|                                         |                        |             Disabled |
+-----------------------------------------+------------------------+----------------------+
                                                                                         
+-----------------------------------------------------------------------------------------+
| Processes:                                                                              |
|  GPU   GI   CI              PID   Type   Process name                        GPU Memory |
|        ID   ID                                                               Usage      |
|=========================================================================================|
|  No running processes found                                                             |
+-----------------------------------------------------------------------------------------+
-----------------------
Starting evaluation for language: swahili
Sample limit: 10
Data directory: /home/vacl2/multimodal_translation/services/data/languages
NMT model: multilang_finetuned_final
TTS model: MULTILINGUAL_TRAINING_11_5-November-05-2025_10+57AM-cc09632
Execution ID: eval_20251119_113303 (shared across languages)

2025-11-19 11:33:35,497 - __main__ - INFO - Using provided execution ID: eval_20251119_113303
2025-11-19 11:33:35,498 - __main__ - INFO - 
============================================================
2025-11-19 11:33:35,498 - __main__ - INFO - Evaluating predictions for SWAHILI
2025-11-19 11:33:35,498 - __main__ - INFO - ============================================================
2025-11-19 11:33:35,510 - __main__ - INFO - Results will be saved to: results/eval_20251119_113303/swahili
2025-11-19 11:33:35,511 - scripts.data_loader - INFO - Loading predictions from /home/vacl2/multimodal_translation/services/data/languages/swahili/nmt_predictions_multilang_finetuned_final.csv
2025-11-19 11:33:35,548 - scripts.data_loader - INFO - Loaded 1864 prediction samples for swahili
2025-11-19 11:33:39,487 - scripts.data_loader - INFO - Successfully created 1864 samples for swahili
2025-11-19 11:33:39,487 - __main__ - INFO - Limiting evaluation to 10 samples
2025-11-19 11:33:39,490 - __main__ - INFO - Evaluating 10 samples of type 'audio_to_audio'
2025-11-19 11:33:39,490 - __main__ - INFO - Metrics to compute: ['bleu', 'chrf', 'comet', 'mcd', 'blaser']
2025-11-19 11:33:39,497 - __main__ - INFO - Initialized text metrics evaluator
2025-11-19 11:33:39,663 - __main__ - INFO - Initialized COMET evaluator
2025-11-19 11:33:39,663 - __main__ - INFO - Initialized audio metrics evaluator
2025-11-19 11:33:39,665 - __main__ - INFO - Initialized BLASER evaluator
2025-11-19 11:33:39,665 - __main__ - INFO - Valid samples: 10, Skipped: 0
2025-11-19 11:33:39,665 - __main__ - INFO - Computing BLEU scores...
2025-11-19 11:33:39,667 - sacrebleu - WARNING - It is recommended to enable `effective_order` for sentence-level BLEU.
2025-11-19 11:33:39,668 - sacrebleu - WARNING - It is recommended to enable `effective_order` for sentence-level BLEU.
2025-11-19 11:33:39,668 - sacrebleu - WARNING - It is recommended to enable `effective_order` for sentence-level BLEU.
2025-11-19 11:33:39,668 - sacrebleu - WARNING - It is recommended to enable `effective_order` for sentence-level BLEU.
2025-11-19 11:33:39,668 - sacrebleu - WARNING - It is recommended to enable `effective_order` for sentence-level BLEU.
2025-11-19 11:33:39,668 - sacrebleu - WARNING - It is recommended to enable `effective_order` for sentence-level BLEU.
2025-11-19 11:33:39,668 - sacrebleu - WARNING - It is recommended to enable `effective_order` for sentence-level BLEU.
2025-11-19 11:33:39,668 - sacrebleu - WARNING - It is recommended to enable `effective_order` for sentence-level BLEU.
2025-11-19 11:33:39,668 - sacrebleu - WARNING - It is recommended to enable `effective_order` for sentence-level BLEU.
2025-11-19 11:33:39,669 - sacrebleu - WARNING - It is recommended to enable `effective_order` for sentence-level BLEU.
2025-11-19 11:33:39,669 - __main__ - INFO - Computing chrF scores...
2025-11-19 11:33:39,676 - __main__ - INFO - Computing COMET scores...
/home/vacl2/multimodal_translation/services/evaluation/.venv/lib64/python3.11/site-packages/torchmetrics/utilities/imports.py:23: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.
  from pkg_resources import DistributionNotFound, get_distribution
2025-11-19 11:34:02,104 - scripts.comet_evaluator - INFO - Loading COMET model: McGill-NLP/ssa-comet-qe
2025-11-19 11:34:09,557 - comet.models.base - INFO - Encoder model frozen.
2025-11-19 11:34:10,554 - scripts.comet_evaluator - INFO - COMET model loaded successfully on cuda
2025-11-19 11:34:10,554 - scripts.comet_evaluator - INFO - Computing COMET scores for 10 samples...
2025-11-19 11:34:10,764 - pytorch_lightning.utilities.rank_zero - INFO - ðŸ’¡ Tip: For seamless cloud uploads and versioning, try installing [litmodels](https://pypi.org/project/litmodels/) to enable LitModelCheckpoint, which syncs automatically with the Lightning model registry.
2025-11-19 11:34:10,822 - pytorch_lightning.utilities.rank_zero - INFO - GPU available: True (cuda), used: True
2025-11-19 11:34:10,822 - pytorch_lightning.utilities.rank_zero - INFO - TPU available: False, using: 0 TPU cores
2025-11-19 11:34:10,832 - pytorch_lightning.utilities.rank_zero - INFO - You are using a CUDA device ('NVIDIA A100-SXM4-80GB') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision
2025-11-19 11:34:10,833 - pytorch_lightning.accelerators.cuda - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
2025-11-19 11:34:10,843 - pytorch_lightning.trainer.connectors.signal_connector - INFO - SLURM auto-requeueing enabled. Setting signal handlers.
Predicting: 0it [00:00, ?it/s]Predicting: 0it [00:00, ?it/s]Predicting DataLoader 0:   0%|          | 0/2 [00:00<?, ?it/s]Predicting DataLoader 0:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 1/2 [00:00<00:00,  2.27it/s]Predicting DataLoader 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00,  4.20it/s]Predicting DataLoader 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00,  4.19it/s]
2025-11-19 11:34:12,975 - __main__ - INFO - Computing MCD scores...
2025-11-19 11:34:12,975 - __main__ - INFO - Comparing predicted audio against ground truth audio
2025-11-19 11:34:31,373 - __main__ - INFO - Computing BLASER scores...
2025-11-19 11:34:31,375 - __main__ - INFO - Using predicted audio for BLASER evaluation
2025-11-19 11:34:31,376 - scripts.blaser_evaluator - INFO - Running BLASER evaluation for 10 samples...
2025-11-19 11:35:13,339 - scripts.blaser_evaluator - ERROR - BLASER evaluation failed with return code 1
2025-11-19 11:35:13,341 - scripts.blaser_evaluator - ERROR - STDERR: 2025-11-19 11:34:38,537 - __main__ - INFO - Using device: cuda
2025-11-19 11:34:50,561 - __main__ - INFO - Loading BLASER model: blaser_2_0_qe
2025-11-19 11:34:50,906 - fairseq2 - INFO - Using the cached blaser_2_0_qe. Set `force` to `True` to download again.

2025-11-19 11:34:51,864 - __main__ - INFO - Loading SONAR encoders...
2025-11-19 11:34:51,869 - fairseq2 - INFO - Using the cached text_sonar_basic_encoder. Set `force` to `True` to download again.

2025-11-19 11:34:57,745 - fairseq2 - INFO - Using the cached text_sonar_basic_encoder. Set `force` to `True` to download again.
2025-11-19 11:34:57,809 - __main__ - INFO - Loading speech encoder for language: eng (sonar_speech_encoder_eng)
2025-11-19 11:34:57,814 - fairseq2 - INFO - Using the cached sonar_speech_encoder_eng. Set `force` to `True` to download again.

2025-11-19 11:35:05,137 - __main__ - INFO - Loading speech encoder for language: swa (sonar_speech_encoder_eng)
2025-11-19 11:35:05,141 - fairseq2 - INFO - Using the cached sonar_speech_encoder_eng. Set `force` to `True` to download again.

2025-11-19 11:35:10,450 - __main__ - INFO - Computing SONAR embeddings...
2025-11-19 11:35:10,450 - __main__ - INFO - Processing 10 source audio files...
2025-11-19 11:35:11,357 - __main__ - INFO - Processing 10 target audio files...
2025-11-19 11:35:12,232 - __main__ - INFO - Processing reference texts...
2025-11-19 11:35:12,232 - __main__ - ERROR - Evaluation failed: `lang` must be a supported language, but is swa_Latn instead.
Traceback (most recent call last):
  File "/home/vacl2/multimodal_translation/services/evaluation/blaser/evaluate.py", line 226, in main
    ref_embs = text_encoder.predict(reference_texts, source_lang=target_lang_mapped)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vacl2/multimodal_translation/services/evaluation/blaser/.venv/lib64/python3.11/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/vacl2/multimodal_translation/services/evaluation/blaser/.venv/lib64/python3.11/site-packages/sonar/inference_pipelines/text.py", line 236, in predict
    tokenizer_encoder = self.tokenizer.create_encoder(
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vacl2/multimodal_translation/services/evaluation/blaser/.venv/lib64/python3.11/site-packages/fairseq2/models/nllb/tokenizer.py", line 83, in create_encoder
    raise NotSupportedError(
fairseq2.error.NotSupportedError: `lang` must be a supported language, but is swa_Latn instead.

2025-11-19 11:35:13,341 - scripts.blaser_evaluator - ERROR - Error during BLASER evaluation: BLASER evaluation failed: 2025-11-19 11:34:38,537 - __main__ - INFO - Using device: cuda
2025-11-19 11:34:50,561 - __main__ - INFO - Loading BLASER model: blaser_2_0_qe
2025-11-19 11:34:50,906 - fairseq2 - INFO - Using the cached blaser_2_0_qe. Set `force` to `True` to download again.

2025-11-19 11:34:51,864 - __main__ - INFO - Loading SONAR encoders...
2025-11-19 11:34:51,869 - fairseq2 - INFO - Using the cached text_sonar_basic_encoder. Set `force` to `True` to download again.

2025-11-19 11:34:57,745 - fairseq2 - INFO - Using the cached text_sonar_basic_encoder. Set `force` to `True` to download again.
2025-11-19 11:34:57,809 - __main__ - INFO - Loading speech encoder for language: eng (sonar_speech_encoder_eng)
2025-11-19 11:34:57,814 - fairseq2 - INFO - Using the cached sonar_speech_encoder_eng. Set `force` to `True` to download again.

2025-11-19 11:35:05,137 - __main__ - INFO - Loading speech encoder for language: swa (sonar_speech_encoder_eng)
2025-11-19 11:35:05,141 - fairseq2 - INFO - Using the cached sonar_speech_encoder_eng. Set `force` to `True` to download again.

2025-11-19 11:35:10,450 - __main__ - INFO - Computing SONAR embeddings...
2025-11-19 11:35:10,450 - __main__ - INFO - Processing 10 source audio files...
2025-11-19 11:35:11,357 - __main__ - INFO - Processing 10 target audio files...
2025-11-19 11:35:12,232 - __main__ - INFO - Processing reference texts...
2025-11-19 11:35:12,232 - __main__ - ERROR - Evaluation failed: `lang` must be a supported language, but is swa_Latn instead.
Traceback (most recent call last):
  File "/home/vacl2/multimodal_translation/services/evaluation/blaser/evaluate.py", line 226, in main
    ref_embs = text_encoder.predict(reference_texts, source_lang=target_lang_mapped)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vacl2/multimodal_translation/services/evaluation/blaser/.venv/lib64/python3.11/site-packages/torch/utils/_contextlib.py", line 120, in decorate_context
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/vacl2/multimodal_translation/services/evaluation/blaser/.venv/lib64/python3.11/site-packages/sonar/inference_pipelines/text.py", line 236, in predict
    tokenizer_encoder = self.tokenizer.create_encoder(
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vacl2/multimodal_translation/services/evaluation/blaser/.venv/lib64/python3.11/site-packages/fairseq2/models/nllb/tokenizer.py", line 83, in create_encoder
    raise NotSupportedError(
fairseq2.error.NotSupportedError: `lang` must be a supported language, but is swa_Latn instead.

2025-11-19 11:35:13,349 - __main__ - INFO - Saved summary to results/eval_20251119_113303/swahili/summary.json
2025-11-19 11:35:13,366 - __main__ - INFO - Saved detailed results to results/eval_20251119_113303/swahili/detailed_results.csv
2025-11-19 11:35:13,372 - __main__ - INFO - Saved full results to results/eval_20251119_113303/swahili/per_sample_results.json
2025-11-19 11:35:13,372 - __main__ - INFO - Generating visualizations...
2025-11-19 11:35:13,373 - __main__ - INFO - Using primary metric for quality categorization: blaser
2025-11-19 11:35:14,535 - scripts.visualizations - INFO - Saved quality dashboard to results/eval_20251119_113303/swahili/visualizations/quality_dashboard.png
2025-11-19 11:35:14,999 - scripts.visualizations - INFO - Saved normalized metrics comparison to results/eval_20251119_113303/swahili/visualizations/normalized_metrics.png
2025-11-19 11:35:15,311 - scripts.visualizations - INFO - Saved metrics comparison chart to results/eval_20251119_113303/swahili/visualizations/metrics_comparison.png
2025-11-19 11:35:15,537 - scripts.visualizations - INFO - Saved metrics table to results/eval_20251119_113303/swahili/visualizations/metrics_table.png
2025-11-19 11:35:16,000 - scripts.visualizations - INFO - Saved BLEU distribution to results/eval_20251119_113303/swahili/visualizations/bleu_distribution.png
2025-11-19 11:35:16,501 - scripts.visualizations - INFO - Saved CHRF distribution to results/eval_20251119_113303/swahili/visualizations/chrf_distribution.png
2025-11-19 11:35:16,970 - scripts.visualizations - INFO - Saved COMET distribution to results/eval_20251119_113303/swahili/visualizations/comet_distribution.png
2025-11-19 11:35:17,468 - scripts.visualizations - INFO - Saved MCD distribution to results/eval_20251119_113303/swahili/visualizations/mcd_distribution.png
2025-11-19 11:35:17,916 - scripts.visualizations - INFO - Saved BLASER distribution to results/eval_20251119_113303/swahili/visualizations/blaser_distribution.png
2025-11-19 11:35:18,567 - scripts.visualizations - INFO - Saved per-sample heatmap to results/eval_20251119_113303/swahili/visualizations/per_sample_heatmap.png
2025-11-19 11:35:18,567 - scripts.visualizations - INFO - All visualizations saved to results/eval_20251119_113303/swahili/visualizations
2025-11-19 11:35:18,588 - scripts.visualizations - INFO - Saved HTML report to results/eval_20251119_113303/swahili/summary_report.html
2025-11-19 11:35:18,588 - __main__ - INFO - Generated HTML report at results/eval_20251119_113303/swahili/summary_report.html
2025-11-19 11:35:18,601 - __main__ - INFO - Updated manifest: results/eval_20251119_113303/manifest.json

============================================================
EVALUATION COMPLETE - swahili
============================================================
Execution ID: eval_20251119_113303
Run ID: run_20251119_113335
Samples evaluated: 10/10

Aggregate Scores:
  BLEU: 60.465
  CHRF: 80.573
  COMET: 0.688
  MCD: 13.891
  BLASER: 0.000

Results saved to: results/eval_20251119_113303/swahili
2025-11-19 11:35:18,601 - __main__ - INFO - Generating overall summary across all languages...
2025-11-19 11:35:18,612 - __main__ - INFO - Saved overall summary: results/eval_20251119_113303/overall_summary.json

======================================================================
OVERALL SUMMARY - ALL LANGUAGES
======================================================================
Execution ID: eval_20251119_113303
Languages evaluated: 1
Total samples: 40
Total valid samples: 40

Average Scores Across Languages:
  BLEU:
    Mean:  60.465
    Range: 60.465 - 60.465
  COMET:
    Mean:  0.688
    Range: 0.688 - 0.688
  CHRF:
    Mean:  80.573
    Range: 80.573 - 80.573
  MCD:
    Mean:  13.891
    Range: 13.891 - 13.891
  BLASER:
    Mean:  0.000
    Range: 0.000 - 0.000

Per-Language Breakdown:
  IGBO:
    Samples: 10/10
    BLEU: 42.911
    CHRF: 65.590
    COMET: 0.609
    MCD: 12.417
    BLASER: 0.000
  EFIK:
    Samples: 10/10
    BLEU: 23.224
    CHRF: 51.757
    COMET: 0.574
    MCD: 12.187
    BLASER: 2.192
  XHOSA:
    Samples: 10/10
    BLEU: 26.979
    CHRF: 68.190
    COMET: 0.645
    MCD: 11.753
    BLASER: 2.191
  SWAHILI:
    Samples: 10/10
    BLEU: 60.465
    CHRF: 80.573
    COMET: 0.688
    MCD: 13.891
    BLASER: 0.000

Results directory: results/eval_20251119_113303
Overall summary: results/eval_20251119_113303/overall_summary.json

============================================================
ALL EVALUATIONS COMPLETE
============================================================
Results directory: results/eval_20251119_113303/swahili

=========================================================
Evaluation finished for swahili
=========================================================
