=========================================================
SLURM JOB ID: 8780330
JOB NAME: eval_predictions
Running on nodes: cs-1-2
Number of GPUs allocated: 1
=========================================================
--- Python and Torch Diagnostics ---
/usr/bin/python
PyTorch version: 2.9.1+cu128
CUDA available: True
Number of GPUs: 1
------------------------------------
--- GPU Diagnostics ---
Mon Dec  1 21:17:15 2025       
+-----------------------------------------------------------------------------------------+
| NVIDIA-SMI 570.195.03             Driver Version: 570.195.03     CUDA Version: 12.8     |
|-----------------------------------------+------------------------+----------------------+
| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |
| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |
|                                         |                        |               MIG M. |
|=========================================+========================+======================|
|   0  NVIDIA A100-SXM4-80GB          Off |   00000000:46:00.0 Off |                    0 |
| N/A   28C    P0             59W /  400W |       0MiB /  81920MiB |      0%      Default |
|                                         |                        |             Disabled |
+-----------------------------------------+------------------------+----------------------+
                                                                                         
+-----------------------------------------------------------------------------------------+
| Processes:                                                                              |
|  GPU   GI   CI              PID   Type   Process name                        GPU Memory |
|        ID   ID                                                               Usage      |
|=========================================================================================|
|  No running processes found                                                             |
+-----------------------------------------------------------------------------------------+
-----------------------
Starting evaluation for language: efik
Sample limit: 10
Data directory: /home/vacl2/multimodal_translation/services/data/languages
NMT model: multilang_finetuned_final
TTS model: MULTILINGUAL_TRAINING_11_5-November-05-2025_10+57AM-cc09632
Execution ID: auto-generated (unique for this language)

2025-12-01 21:17:30,145 - __main__ - INFO - Auto-generated execution ID: eval_20251201_211730
2025-12-01 21:17:30,154 - __main__ - INFO - Initialized manifest: results/eval_20251201_211730/manifest.json
2025-12-01 21:17:30,155 - __main__ - INFO - 
============================================================
2025-12-01 21:17:30,155 - __main__ - INFO - Evaluating predictions for EFIK
2025-12-01 21:17:30,155 - __main__ - INFO - ============================================================
2025-12-01 21:17:30,166 - __main__ - INFO - Results will be saved to: results/eval_20251201_211730/efik
2025-12-01 21:17:30,168 - scripts.data_loader - INFO - Loading predictions from /home/vacl2/multimodal_translation/services/data/languages/efik/nmt_predictions_multilang_finetuned_final.csv
2025-12-01 21:17:30,297 - scripts.data_loader - INFO - Loaded 3248 prediction samples for efik
2025-12-01 21:17:36,858 - scripts.data_loader - INFO - Successfully created 3248 samples for efik
2025-12-01 21:17:36,859 - __main__ - INFO - Limiting evaluation to 10 samples
2025-12-01 21:17:36,867 - pipeline - INFO - Evaluating 10 samples of type 'audio_to_audio'
2025-12-01 21:17:36,867 - pipeline - INFO - Metrics to compute: ['bleu', 'chrf', 'comet', 'mcd', 'blaser']
2025-12-01 21:17:36,876 - pipeline - INFO - Initialized text metrics evaluator
2025-12-01 21:17:37,259 - pipeline - INFO - Initialized COMET evaluator
2025-12-01 21:17:37,259 - pipeline - INFO - Initialized audio metrics evaluator
2025-12-01 21:17:37,265 - pipeline - INFO - Initialized BLASER evaluator
2025-12-01 21:17:37,266 - pipeline - INFO - Valid samples: 10, Skipped: 0
2025-12-01 21:17:37,266 - pipeline - INFO - Computing BLEU scores...
2025-12-01 21:17:37,267 - sacrebleu - WARNING - It is recommended to enable `effective_order` for sentence-level BLEU.
2025-12-01 21:17:37,267 - sacrebleu - WARNING - It is recommended to enable `effective_order` for sentence-level BLEU.
2025-12-01 21:17:37,268 - sacrebleu - WARNING - It is recommended to enable `effective_order` for sentence-level BLEU.
2025-12-01 21:17:37,268 - sacrebleu - WARNING - It is recommended to enable `effective_order` for sentence-level BLEU.
2025-12-01 21:17:37,268 - sacrebleu - WARNING - It is recommended to enable `effective_order` for sentence-level BLEU.
2025-12-01 21:17:37,268 - sacrebleu - WARNING - It is recommended to enable `effective_order` for sentence-level BLEU.
2025-12-01 21:17:37,268 - sacrebleu - WARNING - It is recommended to enable `effective_order` for sentence-level BLEU.
2025-12-01 21:17:37,268 - sacrebleu - WARNING - It is recommended to enable `effective_order` for sentence-level BLEU.
2025-12-01 21:17:37,268 - sacrebleu - WARNING - It is recommended to enable `effective_order` for sentence-level BLEU.
2025-12-01 21:17:37,268 - sacrebleu - WARNING - It is recommended to enable `effective_order` for sentence-level BLEU.
2025-12-01 21:17:37,268 - pipeline - INFO - Computing chrF scores...
2025-12-01 21:17:37,273 - pipeline - INFO - Computing COMET scores...
/home/vacl2/multimodal_translation/services/evaluation/.venv/lib64/python3.11/site-packages/torchmetrics/utilities/imports.py:23: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.
  from pkg_resources import DistributionNotFound, get_distribution
2025-12-01 21:18:06,645 - scripts.comet_evaluator - INFO - Loading COMET model: McGill-NLP/ssa-comet-qe
2025-12-01 21:18:17,537 - comet.models.base - INFO - Encoder model frozen.
2025-12-01 21:18:18,765 - scripts.comet_evaluator - INFO - COMET model loaded successfully on cuda
2025-12-01 21:18:18,765 - scripts.comet_evaluator - INFO - Computing COMET scores for 10 samples...
2025-12-01 21:18:18,977 - pytorch_lightning.utilities.rank_zero - INFO - ðŸ’¡ Tip: For seamless cloud uploads and versioning, try installing [litmodels](https://pypi.org/project/litmodels/) to enable LitModelCheckpoint, which syncs automatically with the Lightning model registry.
2025-12-01 21:18:19,090 - pytorch_lightning.utilities.rank_zero - INFO - GPU available: True (cuda), used: True
2025-12-01 21:18:19,090 - pytorch_lightning.utilities.rank_zero - INFO - TPU available: False, using: 0 TPU cores
2025-12-01 21:18:19,101 - pytorch_lightning.utilities.rank_zero - INFO - You are using a CUDA device ('NVIDIA A100-SXM4-80GB') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision
2025-12-01 21:18:19,102 - pytorch_lightning.accelerators.cuda - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
2025-12-01 21:18:19,143 - pytorch_lightning.trainer.connectors.signal_connector - INFO - SLURM auto-requeueing enabled. Setting signal handlers.
Predicting: 0it [00:00, ?it/s]Predicting: 0it [00:00, ?it/s]Predicting DataLoader 0:   0%|          | 0/2 [00:00<?, ?it/s]Predicting DataLoader 0:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 1/2 [00:00<00:00,  1.05it/s]Predicting DataLoader 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:01<00:00,  1.99it/s]Predicting DataLoader 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:01<00:00,  1.99it/s]
2025-12-01 21:18:21,683 - pipeline - INFO - Computing MCD scores...
2025-12-01 21:18:21,683 - pipeline - INFO - Comparing predicted audio against ground truth audio
2025-12-01 21:18:34,088 - pipeline - INFO - Computing BLASER scores...
2025-12-01 21:18:34,088 - pipeline - INFO - Using predicted audio for BLASER evaluation
2025-12-01 21:18:34,088 - scripts.blaser_evaluator - INFO - Running BLASER evaluation for 10 samples...
2025-12-01 21:19:35,031 - scripts.blaser_evaluator - INFO - BLASER evaluation complete. Corpus score: 1.8150
2025-12-01 21:19:35,041 - pipeline - INFO - Saved summary to results/eval_20251201_211730/efik/summary.json
2025-12-01 21:19:35,062 - pipeline - INFO - Saved detailed results to results/eval_20251201_211730/efik/detailed_results.csv
2025-12-01 21:19:35,069 - pipeline - INFO - Saved full results to results/eval_20251201_211730/efik/per_sample_results.json
2025-12-01 21:19:35,069 - pipeline - INFO - Generating visualizations...
2025-12-01 21:19:35,069 - pipeline - INFO - Using primary metric for quality categorization: blaser
/home/vacl2/multimodal_translation/services/evaluation/scripts/visualizations.py:301: FutureWarning: 

Passing `palette` without assigning `hue` is deprecated and will be removed in v0.14.0. Assign the `x` variable to `hue` and set `legend=False` for the same effect.

  sns.violinplot(data=plot_df, x='Metric', y='Normalized Score',
2025-12-01 21:19:35,674 - scripts.visualizations - INFO - Saved all-metrics overview to results/eval_20251201_211730/efik/visualizations/all_metrics_overview.png
2025-12-01 21:19:36,951 - scripts.visualizations - INFO - Saved quality dashboard to results/eval_20251201_211730/efik/visualizations/quality_dashboard.png
2025-12-01 21:19:37,317 - scripts.visualizations - INFO - Saved metrics comparison chart to results/eval_20251201_211730/efik/visualizations/metrics_comparison.png
2025-12-01 21:19:37,535 - scripts.visualizations - INFO - Saved metrics table to results/eval_20251201_211730/efik/visualizations/metrics_table.png
2025-12-01 21:19:38,054 - scripts.visualizations - INFO - Saved BLEU distribution to results/eval_20251201_211730/efik/visualizations/bleu_distribution.png
2025-12-01 21:19:38,545 - scripts.visualizations - INFO - Saved CHRF distribution to results/eval_20251201_211730/efik/visualizations/chrf_distribution.png
2025-12-01 21:19:38,995 - scripts.visualizations - INFO - Saved COMET distribution to results/eval_20251201_211730/efik/visualizations/comet_distribution.png
2025-12-01 21:19:39,478 - scripts.visualizations - INFO - Saved MCD distribution to results/eval_20251201_211730/efik/visualizations/mcd_distribution.png
2025-12-01 21:19:39,921 - scripts.visualizations - INFO - Saved BLASER distribution to results/eval_20251201_211730/efik/visualizations/blaser_distribution.png
2025-12-01 21:19:39,921 - scripts.visualizations - INFO - All visualizations saved to results/eval_20251201_211730/efik/visualizations
2025-12-01 21:19:39,941 - scripts.visualizations - INFO - Saved HTML report to results/eval_20251201_211730/efik/summary_report.html
2025-12-01 21:19:39,941 - pipeline - INFO - Generated HTML report at results/eval_20251201_211730/efik/summary_report.html
2025-12-01 21:19:39,949 - __main__ - INFO - Updated manifest: results/eval_20251201_211730/manifest.json

============================================================
EVALUATION COMPLETE - efik
============================================================
Execution ID: eval_20251201_211730
Run ID: run_20251201_211730
Samples evaluated: 10/10

Aggregate Scores:
  BLEU: 23.224
  CHRF: 51.757
  COMET: 0.574
  MCD: 12.187
  BLASER: 1.815

Results saved to: results/eval_20251201_211730/efik
2025-12-01 21:19:39,949 - __main__ - INFO - 
============================================================
2025-12-01 21:19:39,949 - __main__ - INFO - Evaluating predictions for IGBO
2025-12-01 21:19:39,949 - __main__ - INFO - ============================================================
2025-12-01 21:19:39,961 - __main__ - INFO - Results will be saved to: results/eval_20251201_211730/igbo
2025-12-01 21:19:39,964 - scripts.data_loader - INFO - Loading predictions from /home/vacl2/multimodal_translation/services/data/languages/igbo/nmt_predictions_multilang_finetuned_final.csv
2025-12-01 21:19:40,042 - scripts.data_loader - INFO - Loaded 2948 prediction samples for igbo
2025-12-01 21:19:45,713 - scripts.data_loader - INFO - Successfully created 2948 samples for igbo
2025-12-01 21:19:45,714 - __main__ - INFO - Limiting evaluation to 10 samples
2025-12-01 21:19:45,718 - pipeline - INFO - Evaluating 10 samples of type 'audio_to_audio'
2025-12-01 21:19:45,719 - pipeline - INFO - Metrics to compute: ['bleu', 'chrf', 'comet', 'mcd', 'blaser']
2025-12-01 21:19:45,719 - pipeline - INFO - Initialized text metrics evaluator
2025-12-01 21:19:45,720 - pipeline - INFO - Initialized COMET evaluator
2025-12-01 21:19:45,720 - pipeline - INFO - Initialized audio metrics evaluator
2025-12-01 21:19:45,721 - pipeline - INFO - Initialized BLASER evaluator
2025-12-01 21:19:45,721 - pipeline - INFO - Valid samples: 10, Skipped: 0
2025-12-01 21:19:45,721 - pipeline - INFO - Computing BLEU scores...
2025-12-01 21:19:45,723 - sacrebleu - WARNING - It is recommended to enable `effective_order` for sentence-level BLEU.
2025-12-01 21:19:45,723 - sacrebleu - WARNING - It is recommended to enable `effective_order` for sentence-level BLEU.
2025-12-01 21:19:45,723 - sacrebleu - WARNING - It is recommended to enable `effective_order` for sentence-level BLEU.
2025-12-01 21:19:45,724 - sacrebleu - WARNING - It is recommended to enable `effective_order` for sentence-level BLEU.
2025-12-01 21:19:45,724 - sacrebleu - WARNING - It is recommended to enable `effective_order` for sentence-level BLEU.
2025-12-01 21:19:45,724 - sacrebleu - WARNING - It is recommended to enable `effective_order` for sentence-level BLEU.
2025-12-01 21:19:45,724 - sacrebleu - WARNING - It is recommended to enable `effective_order` for sentence-level BLEU.
2025-12-01 21:19:45,724 - sacrebleu - WARNING - It is recommended to enable `effective_order` for sentence-level BLEU.
2025-12-01 21:19:45,724 - sacrebleu - WARNING - It is recommended to enable `effective_order` for sentence-level BLEU.
2025-12-01 21:19:45,724 - sacrebleu - WARNING - It is recommended to enable `effective_order` for sentence-level BLEU.
2025-12-01 21:19:45,725 - pipeline - INFO - Computing chrF scores...
2025-12-01 21:19:45,730 - pipeline - INFO - Computing COMET scores...
2025-12-01 21:19:45,730 - scripts.comet_evaluator - INFO - Loading COMET model: McGill-NLP/ssa-comet-qe
2025-12-01 21:19:52,984 - comet.models.base - INFO - Encoder model frozen.
2025-12-01 21:19:53,721 - scripts.comet_evaluator - INFO - COMET model loaded successfully on cuda
2025-12-01 21:19:53,721 - scripts.comet_evaluator - INFO - Computing COMET scores for 10 samples...
2025-12-01 21:19:53,731 - pytorch_lightning.utilities.rank_zero - INFO - ðŸ’¡ Tip: For seamless cloud uploads and versioning, try installing [litmodels](https://pypi.org/project/litmodels/) to enable LitModelCheckpoint, which syncs automatically with the Lightning model registry.
2025-12-01 21:19:53,861 - pytorch_lightning.utilities.rank_zero - INFO - GPU available: True (cuda), used: True
2025-12-01 21:19:53,861 - pytorch_lightning.utilities.rank_zero - INFO - TPU available: False, using: 0 TPU cores
2025-12-01 21:19:53,868 - pytorch_lightning.accelerators.cuda - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
2025-12-01 21:19:53,873 - pytorch_lightning.trainer.connectors.signal_connector - INFO - SLURM auto-requeueing enabled. Setting signal handlers.
Predicting: 0it [00:00, ?it/s]Predicting: 0it [00:00, ?it/s]Predicting DataLoader 0:   0%|          | 0/2 [00:00<?, ?it/s]Predicting DataLoader 0:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 1/2 [00:00<00:00, 28.85it/s]Predicting DataLoader 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00, 20.27it/s]Predicting DataLoader 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00, 19.44it/s]
2025-12-01 21:19:55,536 - pipeline - INFO - Computing MCD scores...
2025-12-01 21:19:55,536 - pipeline - INFO - Comparing predicted audio against ground truth audio
2025-12-01 21:20:10,693 - pipeline - INFO - Computing BLASER scores...
2025-12-01 21:20:10,695 - pipeline - INFO - Using predicted audio for BLASER evaluation
2025-12-01 21:20:10,695 - scripts.blaser_evaluator - INFO - Running BLASER evaluation for 10 samples...
2025-12-01 21:20:41,754 - scripts.blaser_evaluator - INFO - BLASER evaluation complete. Corpus score: 2.7902
2025-12-01 21:20:41,763 - pipeline - INFO - Saved summary to results/eval_20251201_211730/igbo/summary.json
2025-12-01 21:20:41,771 - pipeline - INFO - Saved detailed results to results/eval_20251201_211730/igbo/detailed_results.csv
2025-12-01 21:20:41,779 - pipeline - INFO - Saved full results to results/eval_20251201_211730/igbo/per_sample_results.json
2025-12-01 21:20:41,779 - pipeline - INFO - Generating visualizations...
2025-12-01 21:20:41,779 - pipeline - INFO - Using primary metric for quality categorization: blaser
/home/vacl2/multimodal_translation/services/evaluation/scripts/visualizations.py:301: FutureWarning: 

Passing `palette` without assigning `hue` is deprecated and will be removed in v0.14.0. Assign the `x` variable to `hue` and set `legend=False` for the same effect.

  sns.violinplot(data=plot_df, x='Metric', y='Normalized Score',
2025-12-01 21:20:42,193 - scripts.visualizations - INFO - Saved all-metrics overview to results/eval_20251201_211730/igbo/visualizations/all_metrics_overview.png
2025-12-01 21:20:43,475 - scripts.visualizations - INFO - Saved quality dashboard to results/eval_20251201_211730/igbo/visualizations/quality_dashboard.png
2025-12-01 21:20:43,833 - scripts.visualizations - INFO - Saved metrics comparison chart to results/eval_20251201_211730/igbo/visualizations/metrics_comparison.png
2025-12-01 21:20:44,062 - scripts.visualizations - INFO - Saved metrics table to results/eval_20251201_211730/igbo/visualizations/metrics_table.png
2025-12-01 21:20:44,509 - scripts.visualizations - INFO - Saved BLEU distribution to results/eval_20251201_211730/igbo/visualizations/bleu_distribution.png
2025-12-01 21:20:44,997 - scripts.visualizations - INFO - Saved CHRF distribution to results/eval_20251201_211730/igbo/visualizations/chrf_distribution.png
2025-12-01 21:20:45,451 - scripts.visualizations - INFO - Saved COMET distribution to results/eval_20251201_211730/igbo/visualizations/comet_distribution.png
2025-12-01 21:20:45,918 - scripts.visualizations - INFO - Saved MCD distribution to results/eval_20251201_211730/igbo/visualizations/mcd_distribution.png
2025-12-01 21:20:46,364 - scripts.visualizations - INFO - Saved BLASER distribution to results/eval_20251201_211730/igbo/visualizations/blaser_distribution.png
2025-12-01 21:20:46,364 - scripts.visualizations - INFO - All visualizations saved to results/eval_20251201_211730/igbo/visualizations
2025-12-01 21:20:46,378 - scripts.visualizations - INFO - Saved HTML report to results/eval_20251201_211730/igbo/summary_report.html
2025-12-01 21:20:46,378 - pipeline - INFO - Generated HTML report at results/eval_20251201_211730/igbo/summary_report.html
2025-12-01 21:20:46,385 - __main__ - INFO - Updated manifest: results/eval_20251201_211730/manifest.json

============================================================
EVALUATION COMPLETE - igbo
============================================================
Execution ID: eval_20251201_211730
Run ID: run_20251201_211939
Samples evaluated: 10/10

Aggregate Scores:
  BLEU: 42.911
  CHRF: 65.590
  COMET: 0.609
  MCD: 12.417
  BLASER: 2.790

Results saved to: results/eval_20251201_211730/igbo
2025-12-01 21:20:46,386 - __main__ - INFO - 
============================================================
2025-12-01 21:20:46,386 - __main__ - INFO - Evaluating predictions for SWAHILI
2025-12-01 21:20:46,386 - __main__ - INFO - ============================================================
2025-12-01 21:20:46,397 - __main__ - INFO - Results will be saved to: results/eval_20251201_211730/swahili
2025-12-01 21:20:46,398 - scripts.data_loader - INFO - Loading predictions from /home/vacl2/multimodal_translation/services/data/languages/swahili/nmt_predictions_multilang_finetuned_final.csv
2025-12-01 21:20:46,454 - scripts.data_loader - INFO - Loaded 1864 prediction samples for swahili
2025-12-01 21:20:51,865 - scripts.data_loader - INFO - Successfully created 1864 samples for swahili
2025-12-01 21:20:51,866 - __main__ - INFO - Limiting evaluation to 10 samples
2025-12-01 21:20:51,868 - pipeline - INFO - Evaluating 10 samples of type 'audio_to_audio'
2025-12-01 21:20:51,868 - pipeline - INFO - Metrics to compute: ['bleu', 'chrf', 'comet', 'mcd', 'blaser']
2025-12-01 21:20:51,869 - pipeline - INFO - Initialized text metrics evaluator
2025-12-01 21:20:51,870 - pipeline - INFO - Initialized COMET evaluator
2025-12-01 21:20:51,870 - pipeline - INFO - Initialized audio metrics evaluator
2025-12-01 21:20:51,871 - pipeline - INFO - Initialized BLASER evaluator
2025-12-01 21:20:51,872 - pipeline - INFO - Valid samples: 10, Skipped: 0
2025-12-01 21:20:51,872 - pipeline - INFO - Computing BLEU scores...
2025-12-01 21:20:51,874 - sacrebleu - WARNING - It is recommended to enable `effective_order` for sentence-level BLEU.
2025-12-01 21:20:51,874 - sacrebleu - WARNING - It is recommended to enable `effective_order` for sentence-level BLEU.
2025-12-01 21:20:51,874 - sacrebleu - WARNING - It is recommended to enable `effective_order` for sentence-level BLEU.
2025-12-01 21:20:51,874 - sacrebleu - WARNING - It is recommended to enable `effective_order` for sentence-level BLEU.
2025-12-01 21:20:51,874 - sacrebleu - WARNING - It is recommended to enable `effective_order` for sentence-level BLEU.
2025-12-01 21:20:51,874 - sacrebleu - WARNING - It is recommended to enable `effective_order` for sentence-level BLEU.
2025-12-01 21:20:51,874 - sacrebleu - WARNING - It is recommended to enable `effective_order` for sentence-level BLEU.
2025-12-01 21:20:51,875 - sacrebleu - WARNING - It is recommended to enable `effective_order` for sentence-level BLEU.
2025-12-01 21:20:51,875 - sacrebleu - WARNING - It is recommended to enable `effective_order` for sentence-level BLEU.
2025-12-01 21:20:51,875 - sacrebleu - WARNING - It is recommended to enable `effective_order` for sentence-level BLEU.
2025-12-01 21:20:51,875 - pipeline - INFO - Computing chrF scores...
2025-12-01 21:20:51,882 - pipeline - INFO - Computing COMET scores...
2025-12-01 21:20:51,882 - scripts.comet_evaluator - INFO - Loading COMET model: McGill-NLP/ssa-comet-qe
2025-12-01 21:20:59,049 - comet.models.base - INFO - Encoder model frozen.
2025-12-01 21:20:59,805 - scripts.comet_evaluator - INFO - COMET model loaded successfully on cuda
2025-12-01 21:20:59,805 - scripts.comet_evaluator - INFO - Computing COMET scores for 10 samples...
2025-12-01 21:20:59,815 - pytorch_lightning.utilities.rank_zero - INFO - ðŸ’¡ Tip: For seamless cloud uploads and versioning, try installing [litmodels](https://pypi.org/project/litmodels/) to enable LitModelCheckpoint, which syncs automatically with the Lightning model registry.
2025-12-01 21:20:59,943 - pytorch_lightning.utilities.rank_zero - INFO - GPU available: True (cuda), used: True
2025-12-01 21:20:59,944 - pytorch_lightning.utilities.rank_zero - INFO - TPU available: False, using: 0 TPU cores
2025-12-01 21:20:59,952 - pytorch_lightning.accelerators.cuda - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
2025-12-01 21:20:59,957 - pytorch_lightning.trainer.connectors.signal_connector - INFO - SLURM auto-requeueing enabled. Setting signal handlers.
Predicting: 0it [00:00, ?it/s]Predicting: 0it [00:00, ?it/s]Predicting DataLoader 0:   0%|          | 0/2 [00:00<?, ?it/s]Predicting DataLoader 0:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 1/2 [00:00<00:00, 25.12it/s]Predicting DataLoader 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00, 22.39it/s]Predicting DataLoader 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00, 22.19it/s]
2025-12-01 21:21:01,652 - pipeline - INFO - Computing MCD scores...
2025-12-01 21:21:01,652 - pipeline - INFO - Comparing predicted audio against ground truth audio
2025-12-01 21:21:21,413 - pipeline - INFO - Computing BLASER scores...
2025-12-01 21:21:21,414 - pipeline - INFO - Using predicted audio for BLASER evaluation
2025-12-01 21:21:21,415 - scripts.blaser_evaluator - INFO - Running BLASER evaluation for 10 samples...
2025-12-01 21:22:01,253 - scripts.blaser_evaluator - INFO - BLASER evaluation complete. Corpus score: 4.4517
2025-12-01 21:22:01,263 - pipeline - INFO - Saved summary to results/eval_20251201_211730/swahili/summary.json
2025-12-01 21:22:01,275 - pipeline - INFO - Saved detailed results to results/eval_20251201_211730/swahili/detailed_results.csv
2025-12-01 21:22:01,289 - pipeline - INFO - Saved full results to results/eval_20251201_211730/swahili/per_sample_results.json
2025-12-01 21:22:01,289 - pipeline - INFO - Generating visualizations...
2025-12-01 21:22:01,289 - pipeline - INFO - Using primary metric for quality categorization: blaser
/home/vacl2/multimodal_translation/services/evaluation/scripts/visualizations.py:301: FutureWarning: 

Passing `palette` without assigning `hue` is deprecated and will be removed in v0.14.0. Assign the `x` variable to `hue` and set `legend=False` for the same effect.

  sns.violinplot(data=plot_df, x='Metric', y='Normalized Score',
2025-12-01 21:22:01,718 - scripts.visualizations - INFO - Saved all-metrics overview to results/eval_20251201_211730/swahili/visualizations/all_metrics_overview.png
2025-12-01 21:22:03,261 - scripts.visualizations - INFO - Saved quality dashboard to results/eval_20251201_211730/swahili/visualizations/quality_dashboard.png
2025-12-01 21:22:03,634 - scripts.visualizations - INFO - Saved metrics comparison chart to results/eval_20251201_211730/swahili/visualizations/metrics_comparison.png
2025-12-01 21:22:03,863 - scripts.visualizations - INFO - Saved metrics table to results/eval_20251201_211730/swahili/visualizations/metrics_table.png
2025-12-01 21:22:04,315 - scripts.visualizations - INFO - Saved BLEU distribution to results/eval_20251201_211730/swahili/visualizations/bleu_distribution.png
2025-12-01 21:22:04,794 - scripts.visualizations - INFO - Saved CHRF distribution to results/eval_20251201_211730/swahili/visualizations/chrf_distribution.png
2025-12-01 21:22:05,262 - scripts.visualizations - INFO - Saved COMET distribution to results/eval_20251201_211730/swahili/visualizations/comet_distribution.png
2025-12-01 21:22:05,728 - scripts.visualizations - INFO - Saved MCD distribution to results/eval_20251201_211730/swahili/visualizations/mcd_distribution.png
2025-12-01 21:22:06,209 - scripts.visualizations - INFO - Saved BLASER distribution to results/eval_20251201_211730/swahili/visualizations/blaser_distribution.png
2025-12-01 21:22:06,210 - scripts.visualizations - INFO - All visualizations saved to results/eval_20251201_211730/swahili/visualizations
2025-12-01 21:22:06,225 - scripts.visualizations - INFO - Saved HTML report to results/eval_20251201_211730/swahili/summary_report.html
2025-12-01 21:22:06,225 - pipeline - INFO - Generated HTML report at results/eval_20251201_211730/swahili/summary_report.html
2025-12-01 21:22:06,233 - __main__ - INFO - Updated manifest: results/eval_20251201_211730/manifest.json

============================================================
EVALUATION COMPLETE - swahili
============================================================
Execution ID: eval_20251201_211730
Run ID: run_20251201_212046
Samples evaluated: 10/10

Aggregate Scores:
  BLEU: 60.465
  CHRF: 80.573
  COMET: 0.688
  MCD: 13.891
  BLASER: 4.452

Results saved to: results/eval_20251201_211730/swahili
2025-12-01 21:22:06,234 - __main__ - INFO - 
============================================================
2025-12-01 21:22:06,234 - __main__ - INFO - Evaluating predictions for XHOSA
2025-12-01 21:22:06,234 - __main__ - INFO - ============================================================
2025-12-01 21:22:06,246 - __main__ - INFO - Results will be saved to: results/eval_20251201_211730/xhosa
2025-12-01 21:22:06,248 - scripts.data_loader - INFO - Loading predictions from /home/vacl2/multimodal_translation/services/data/languages/xhosa/nmt_predictions_multilang_finetuned_final.csv
2025-12-01 21:22:06,324 - scripts.data_loader - INFO - Loaded 1894 prediction samples for xhosa
2025-12-01 21:22:12,225 - scripts.data_loader - INFO - Successfully created 1894 samples for xhosa
2025-12-01 21:22:12,226 - __main__ - INFO - Limiting evaluation to 10 samples
2025-12-01 21:22:12,230 - pipeline - INFO - Evaluating 10 samples of type 'audio_to_audio'
2025-12-01 21:22:12,230 - pipeline - INFO - Metrics to compute: ['bleu', 'chrf', 'comet', 'mcd', 'blaser']
2025-12-01 21:22:12,230 - pipeline - INFO - Initialized text metrics evaluator
2025-12-01 21:22:12,231 - pipeline - INFO - Initialized COMET evaluator
2025-12-01 21:22:12,231 - pipeline - INFO - Initialized audio metrics evaluator
2025-12-01 21:22:12,232 - pipeline - INFO - Initialized BLASER evaluator
2025-12-01 21:22:12,243 - pipeline - INFO - Valid samples: 10, Skipped: 0
2025-12-01 21:22:12,243 - pipeline - INFO - Computing BLEU scores...
2025-12-01 21:22:12,245 - sacrebleu - WARNING - It is recommended to enable `effective_order` for sentence-level BLEU.
2025-12-01 21:22:12,245 - sacrebleu - WARNING - It is recommended to enable `effective_order` for sentence-level BLEU.
2025-12-01 21:22:12,245 - sacrebleu - WARNING - It is recommended to enable `effective_order` for sentence-level BLEU.
2025-12-01 21:22:12,245 - sacrebleu - WARNING - It is recommended to enable `effective_order` for sentence-level BLEU.
2025-12-01 21:22:12,245 - sacrebleu - WARNING - It is recommended to enable `effective_order` for sentence-level BLEU.
2025-12-01 21:22:12,246 - sacrebleu - WARNING - It is recommended to enable `effective_order` for sentence-level BLEU.
2025-12-01 21:22:12,246 - sacrebleu - WARNING - It is recommended to enable `effective_order` for sentence-level BLEU.
2025-12-01 21:22:12,246 - sacrebleu - WARNING - It is recommended to enable `effective_order` for sentence-level BLEU.
2025-12-01 21:22:12,246 - sacrebleu - WARNING - It is recommended to enable `effective_order` for sentence-level BLEU.
2025-12-01 21:22:12,246 - sacrebleu - WARNING - It is recommended to enable `effective_order` for sentence-level BLEU.
2025-12-01 21:22:12,246 - pipeline - INFO - Computing chrF scores...
2025-12-01 21:22:12,253 - pipeline - INFO - Computing COMET scores...
2025-12-01 21:22:12,253 - scripts.comet_evaluator - INFO - Loading COMET model: McGill-NLP/ssa-comet-qe
2025-12-01 21:22:19,952 - comet.models.base - INFO - Encoder model frozen.
2025-12-01 21:22:20,790 - scripts.comet_evaluator - INFO - COMET model loaded successfully on cuda
2025-12-01 21:22:20,790 - scripts.comet_evaluator - INFO - Computing COMET scores for 10 samples...
2025-12-01 21:22:20,804 - pytorch_lightning.utilities.rank_zero - INFO - ðŸ’¡ Tip: For seamless cloud uploads and versioning, try installing [litmodels](https://pypi.org/project/litmodels/) to enable LitModelCheckpoint, which syncs automatically with the Lightning model registry.
2025-12-01 21:22:20,999 - pytorch_lightning.utilities.rank_zero - INFO - GPU available: True (cuda), used: True
2025-12-01 21:22:20,999 - pytorch_lightning.utilities.rank_zero - INFO - TPU available: False, using: 0 TPU cores
2025-12-01 21:22:21,009 - pytorch_lightning.accelerators.cuda - INFO - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
2025-12-01 21:22:21,013 - pytorch_lightning.trainer.connectors.signal_connector - INFO - SLURM auto-requeueing enabled. Setting signal handlers.
Predicting: 0it [00:00, ?it/s]Predicting: 0it [00:00, ?it/s]Predicting DataLoader 0:   0%|          | 0/2 [00:00<?, ?it/s]Predicting DataLoader 0:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 1/2 [00:00<00:00, 26.65it/s]Predicting DataLoader 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00, 19.38it/s]Predicting DataLoader 0: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [00:00<00:00, 19.31it/s]
2025-12-01 21:22:22,783 - pipeline - INFO - Computing MCD scores...
2025-12-01 21:22:22,784 - pipeline - INFO - Comparing predicted audio against ground truth audio
2025-12-01 21:22:39,196 - pipeline - INFO - Computing BLASER scores...
2025-12-01 21:22:39,197 - pipeline - INFO - Using predicted audio for BLASER evaluation
2025-12-01 21:22:39,197 - scripts.blaser_evaluator - INFO - Running BLASER evaluation for 10 samples...
2025-12-01 21:23:09,681 - scripts.blaser_evaluator - INFO - BLASER evaluation complete. Corpus score: 3.4362
2025-12-01 21:23:09,690 - pipeline - INFO - Saved summary to results/eval_20251201_211730/xhosa/summary.json
2025-12-01 21:23:09,698 - pipeline - INFO - Saved detailed results to results/eval_20251201_211730/xhosa/detailed_results.csv
2025-12-01 21:23:09,705 - pipeline - INFO - Saved full results to results/eval_20251201_211730/xhosa/per_sample_results.json
2025-12-01 21:23:09,705 - pipeline - INFO - Generating visualizations...
2025-12-01 21:23:09,705 - pipeline - INFO - Using primary metric for quality categorization: blaser
/home/vacl2/multimodal_translation/services/evaluation/scripts/visualizations.py:301: FutureWarning: 

Passing `palette` without assigning `hue` is deprecated and will be removed in v0.14.0. Assign the `x` variable to `hue` and set `legend=False` for the same effect.

  sns.violinplot(data=plot_df, x='Metric', y='Normalized Score',
2025-12-01 21:23:10,115 - scripts.visualizations - INFO - Saved all-metrics overview to results/eval_20251201_211730/xhosa/visualizations/all_metrics_overview.png
2025-12-01 21:23:11,348 - scripts.visualizations - INFO - Saved quality dashboard to results/eval_20251201_211730/xhosa/visualizations/quality_dashboard.png
2025-12-01 21:23:11,695 - scripts.visualizations - INFO - Saved metrics comparison chart to results/eval_20251201_211730/xhosa/visualizations/metrics_comparison.png
2025-12-01 21:23:11,923 - scripts.visualizations - INFO - Saved metrics table to results/eval_20251201_211730/xhosa/visualizations/metrics_table.png
2025-12-01 21:23:12,396 - scripts.visualizations - INFO - Saved BLEU distribution to results/eval_20251201_211730/xhosa/visualizations/bleu_distribution.png
2025-12-01 21:23:12,853 - scripts.visualizations - INFO - Saved CHRF distribution to results/eval_20251201_211730/xhosa/visualizations/chrf_distribution.png
2025-12-01 21:23:13,312 - scripts.visualizations - INFO - Saved COMET distribution to results/eval_20251201_211730/xhosa/visualizations/comet_distribution.png
2025-12-01 21:23:13,787 - scripts.visualizations - INFO - Saved MCD distribution to results/eval_20251201_211730/xhosa/visualizations/mcd_distribution.png
2025-12-01 21:23:14,267 - scripts.visualizations - INFO - Saved BLASER distribution to results/eval_20251201_211730/xhosa/visualizations/blaser_distribution.png
2025-12-01 21:23:14,267 - scripts.visualizations - INFO - All visualizations saved to results/eval_20251201_211730/xhosa/visualizations
2025-12-01 21:23:14,284 - scripts.visualizations - INFO - Saved HTML report to results/eval_20251201_211730/xhosa/summary_report.html
2025-12-01 21:23:14,284 - pipeline - INFO - Generated HTML report at results/eval_20251201_211730/xhosa/summary_report.html
2025-12-01 21:23:14,297 - __main__ - INFO - Updated manifest: results/eval_20251201_211730/manifest.json

============================================================
EVALUATION COMPLETE - xhosa
============================================================
Execution ID: eval_20251201_211730
Run ID: run_20251201_212206
Samples evaluated: 10/10

Aggregate Scores:
  BLEU: 26.979
  CHRF: 68.190
  COMET: 0.645
  MCD: 11.753
  BLASER: 3.436

Results saved to: results/eval_20251201_211730/xhosa
2025-12-01 21:23:14,297 - __main__ - INFO - Generating overall summary across all languages...
2025-12-01 21:23:14,320 - __main__ - INFO - Saved overall summary: results/eval_20251201_211730/overall_summary.json
2025-12-01 21:23:14,323 - __main__ - INFO - Generating cross-language visualizations in results/eval_20251201_211730/visualizations
/home/vacl2/multimodal_translation/services/evaluation/scripts/visualizations.py:452: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.
  annot_data = df_raw.applymap(lambda x: f"{x:.2f}" if pd.notna(x) else "N/A")
2025-12-01 21:23:14,893 - scripts.visualizations - INFO - Saved languageÃ—metric heatmap to results/eval_20251201_211730/visualizations/language_metric_heatmap.png

======================================================================
OVERALL SUMMARY - ALL LANGUAGES
======================================================================
Execution ID: eval_20251201_211730
Languages evaluated: 4
Total samples: 40
Total valid samples: 40

Aggregate Statistics Across Languages:
  COMET:
    Mean:   0.629
    Median: 0.627
    Std:    0.049
    Range:  0.574 - 0.688
  BLEU:
    Mean:   38.395
    Median: 34.945
    Std:    17.010
    Range:  23.224 - 60.465
  BLASER:
    Mean:   3.123
    Median: 3.113
    Std:    1.108
    Range:  1.815 - 4.452
  MCD:
    Mean:   12.562
    Median: 12.302
    Std:    0.928
    Range:  11.753 - 13.891
  CHRF:
    Mean:   66.527
    Median: 66.890
    Std:    11.819
    Range:  51.757 - 80.573

Per-Language Breakdown:
  EFIK:
    Samples: 10/10
    BLEU: 23.224
    CHRF: 51.757
    COMET: 0.574
    MCD: 12.187
    BLASER: 1.815
  IGBO:
    Samples: 10/10
    BLEU: 42.911
    CHRF: 65.590
    COMET: 0.609
    MCD: 12.417
    BLASER: 2.790
  SWAHILI:
    Samples: 10/10
    BLEU: 60.465
    CHRF: 80.573
    COMET: 0.688
    MCD: 13.891
    BLASER: 4.452
  XHOSA:
    Samples: 10/10
    BLEU: 26.979
    CHRF: 68.190
    COMET: 0.645
    MCD: 11.753
    BLASER: 3.436

Results directory: results/eval_20251201_211730
Overall summary: results/eval_20251201_211730/overall_summary.json

Cross-language visualizations:
  - LanguageÃ—Metric Heatmap: results/eval_20251201_211730/visualizations/language_metric_heatmap.png

============================================================
ALL EVALUATIONS COMPLETE
============================================================
Results directory: results/eval_20251201_211730

=========================================================
Evaluation finished for efik
=========================================================
