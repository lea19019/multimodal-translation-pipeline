# Multimodal Translation Pipeline
This project will explore modern deep learning methods for building a speech and text translation pipeline for low-resource languages. The pipeline will include three components: Automatic Speech Recognition (ASR), Neural Machine Translation (NMT), and Text-to-Speech (TTS). 

## Phase 1

- Setup environment
- How are we going to connect to hugging face locally?
- How to use the base models?
- Build an app that is capable of receiving an audio file, an input audio stream, or text, then selects the desired language output (audio or text)
- Integrate the base models in that app.
- Read the model's papers 
- Decide some test and evaluating metrics


## Todos:
- System Architecture Design
- Input and Output System
- Pipeline System 
- Models Manager (Placeholder)
- Evaluation System
- Data System for Evaluation 
- Local Dev Env for Models
- Setup Baseline Models 

Goal: **Sep 28**



BlueScore - Translation
WordErrorRate - For ASR
Commet
CHRF

Blaser 2.0 paper - TTS evaluation
text to speech quality metrics - find papers